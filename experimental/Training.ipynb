{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMzPdH9CMI6mv/V4aIz4ILw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Peruk8BVyJYa","cellView":"form"},"outputs":[],"source":["# @title 1. Environment setup and data loading\n","import os\n","import sys\n","import importlib.util\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Project path configuration.\n","DRIVE_FOLDER = \"/content/drive/My Drive/projects/TensorMorph\"\n","LOCAL_FOLDER = \"/content/tensormorph_local\"\n","\n","# Mount Drive for data and schema access.\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# Workspace initialization.\n","os.makedirs(f\"{LOCAL_FOLDER}/experimental\", exist_ok=True)\n","os.makedirs(f\"{LOCAL_FOLDER}/data\", exist_ok=True)\n","\n","# Syncing local experimental scripts and the generated data.\n","print(\"Syncing files from Drive...\")\n","!rsync -av --progress \"{DRIVE_FOLDER}/experimental/\" \"{LOCAL_FOLDER}/experimental/\"\n","!cp -r \"{DRIVE_FOLDER}/data/\"* \"{LOCAL_FOLDER}/data/\"\n","\n","os.chdir(LOCAL_FOLDER)\n","\n","# Direct path import for schema.py to ensure alignment with DataGen.\n","schema_path = os.path.join(LOCAL_FOLDER, \"experimental/schema.py\")\n","spec = importlib.util.spec_from_file_location(\"schema\", schema_path)\n","schema = importlib.util.module_from_spec(spec)\n","try:\n","    spec.loader.exec_module(schema)\n","    global FEATURES, TARGET\n","    FEATURES = schema.FEATURES\n","    TARGET = schema.TARGET\n","    print(f\"Schema loaded: {len(FEATURES)} features identified.\")\n","except Exception as e:\n","    print(f\"Error: Failed to load schema.py: {e}\")\n","\n","# Load the datasets.\n","df_mem = pd.read_csv(\"data/dataset_memory_bound.csv\")\n","df_comp = pd.read_csv(\"data/dataset_compute_bound.csv\")\n","\n","print(f\"Loaded {len(df_mem)} Memory-Bound and {len(df_comp)} Compute-Bound samples.\")\n","print(\"Environment ready.\")"]},{"cell_type":"code","source":["# @title 2. Data preprocessing and feature engineering\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","# Constants for the 70/15/15 split.\n","TRAIN_RATIO = 0.7\n","VAL_RATIO = 0.15\n","TEST_RATIO = 0.15\n","SEED = 42\n","NORMALIZE = True\n","\n","def prepare_dataset(df, feature_cols, target_col):\n","    \"\"\"\n","    Splits data into train, validation, and test sets.\n","    \"\"\"\n","    X = df[feature_cols].values\n","    y = df[target_col].values\n","\n","    # Isolate the test set first.\n","    X_temp, X_test, y_temp, y_test = train_test_split(\n","        X, y, test_size=TEST_RATIO, random_state=SEED\n","    )\n","\n","    # Split the remainder into train and val.\n","    relative_val_ratio = VAL_RATIO / (TRAIN_RATIO + VAL_RATIO)\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X_temp, y_temp, test_size=relative_val_ratio, random_state=SEED\n","    )\n","\n","    scaler = None\n","    if NORMALIZE:\n","        scaler = StandardScaler()\n","        # Scale based on training distribution.\n","        X_train = scaler.fit_transform(X_train)\n","        X_val = scaler.transform(X_val)\n","        X_test = scaler.transform(X_test)\n","\n","    return X_train, X_val, X_test, y_train, y_val, y_test, scaler\n","\n","# Process both hardware targets.\n","res_mem = prepare_dataset(df_mem, FEATURES, TARGET)\n","X_train_mem, X_val_mem, X_test_mem, y_train_mem, y_val_mem, y_test_mem, scaler_mem = res_mem\n","\n","res_comp = prepare_dataset(df_comp, FEATURES, TARGET)\n","X_train_comp, X_val_comp, X_test_comp, y_train_comp, y_val_comp, y_test_comp, scaler_comp = res_comp\n","\n","# Print explicit counts.\n","print(f\"Memory split: {len(X_train_mem)} train, {len(X_val_mem)} val, {len(X_test_mem)} test.\")\n","print(f\"Compute split: {len(X_train_comp)} train, {len(X_val_comp)} val, {len(X_test_comp)} test.\")"],"metadata":{"id":"dQyW_rMRyiWZ","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title 3. Model training and evaluation\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","# Ensemble hyperparameters.\n","N_TREES = 100\n","LR = 0.1\n","DEPTH = 4\n","\n","def run_training(X_train, X_val, X_test, y_train, y_val, y_test, label):\n","    model = GradientBoostingRegressor(\n","        n_estimators=N_TREES,\n","        learning_rate=LR,\n","        max_depth=DEPTH,\n","        random_state=SEED\n","    )\n","\n","    # Fit the model.\n","    model.fit(X_train, y_train)\n","\n","    # Check validation performance.\n","    val_preds = model.predict(X_val)\n","    val_r2 = r2_score(y_val, val_preds)\n","\n","    # Unbiased final test.\n","    test_preds = model.predict(X_test)\n","    test_r2 = r2_score(y_test, test_preds)\n","    test_mse = mean_squared_error(y_test, test_preds)\n","\n","    print(f\"Results for {label}:\")\n","    print(f\"  Val R2:  {val_r2:.4f}\")\n","    print(f\"  Test R2: {test_r2:.4f}\")\n","    print(f\"  Test MSE: {test_mse:.4f}\\n\")\n","\n","    return model\n","\n","# Train the specialized advisors.\n","model_mem = run_training(\n","    X_train_mem, X_val_mem, X_test_mem, y_train_mem, y_val_mem, y_test_mem, \"Memory-Bound\"\n",")\n","\n","model_comp = run_training(\n","    X_train_comp, X_val_comp, X_test_comp, y_train_comp, y_val_comp, y_test_comp, \"Compute-Bound\"\n",")"],"metadata":{"id":"tH9NJfyey0Jv","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title 4. Feature importance and analysis\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def plot_importance(model, feature_names, title, ax):\n","    # Extract importance scores.\n","    importances = model.feature_importances_\n","    indices = np.argsort(importances)\n","\n","    # Create horizontal bar chart.\n","    ax.barh(range(len(indices)), importances[indices], color='steelblue', align='center')\n","    ax.set_yticks(range(len(indices)))\n","    ax.set_yticklabels([feature_names[i] for i in indices])\n","    ax.set_title(title)\n","    ax.set_xlabel(\"Importance score\")\n","    ax.grid(axis='x', alpha=0.3)\n","\n","# Compare hardware profiles.\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n","\n","plot_importance(model_mem, FEATURES, \"Memory-Bound features\", ax1)\n","plot_importance(model_comp, FEATURES, \"Compute-Bound features\", ax2)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"cellView":"form","id":"xPuKtmVaDJpy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title 5. Model persistence\n","import joblib\n","import os\n","\n","# Create local directory.\n","os.makedirs(\"models\", exist_ok=True)\n","\n","# Save Memory-Bound artifacts.\n","joblib.dump(model_mem, \"models/model_mem.joblib\")\n","joblib.dump(scaler_mem, \"models/scaler_mem.joblib\")\n","\n","# Save Compute-Bound artifacts.\n","joblib.dump(model_comp, \"models/model_comp.joblib\")\n","joblib.dump(scaler_comp, \"models/scaler_comp.joblib\")\n","\n","# Ensure Drive directory exists.\n","drive_models_path = f\"{DRIVE_FOLDER}/models\"\n","os.makedirs(drive_models_path, exist_ok=True)\n","\n","# Sync to Drive.\n","!cp -r models/* \"{drive_models_path}/\"\n","\n","print(f\"Models and scalers persisted to {drive_models_path}.\")"],"metadata":{"cellView":"form","id":"ExiN6PLjEWqG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title 6. Model transpilation and C++ export\n","import datetime\n","import os\n","\n","def export_to_cpp(model, scaler, feature_names, class_name, filename, profile_id):\n","    \"\"\"\n","    Converts a Gradient Boosting model and its scaler to a C++ header\n","    that implements the full Advisor interface.\n","    \"\"\"\n","    init_val = model.init_.constant_[0][0]\n","    n_trees = len(model.estimators_)\n","    means = scaler.mean_\n","    scales = scaler.scale_\n","\n","    with open(filename, 'w') as f:\n","        f.write(f\"// Autogenerated - DO NOT EDIT. Created: {datetime.date.today()}\\n\")\n","        f.write(f\"#pragma once\\n\")\n","        f.write(f\"#include <vector>\\n\")\n","        f.write(f\"#include <string>\\n\")\n","        f.write(f'#include \"experimental/Advisor.h\"\\n\\n')\n","\n","        f.write(f\"class {class_name} : public Advisor {{\\n\")\n","        f.write(f\"public:\\n\")\n","\n","        # Implementation of the Advisor interface.\n","        f.write(f\"    float Predict(const std::vector<float>& features) const override {{\\n\")\n","        f.write(f\"        return predict(features);\\n\")\n","        f.write(f\"    }}\\n\\n\")\n","\n","        f.write(f\"    std::string GetProfileName() const override {{\\n\")\n","        f.write(f'        return \"{profile_id}\";\\n')\n","        f.write(f\"    }}\\n\\n\")\n","\n","        f.write(f\"    static float predict(const std::vector<float>& input) {{\\n\")\n","        f.write(f\"        float x[{len(feature_names)}];\\n\")\n","        for i in range(len(feature_names)):\n","            f.write(f\"        x[{i}] = (input[{i}] - {means[i]:.8f}f) / {scales[i]:.8f}f;\\n\")\n","\n","        f.write(f\"\\n        float score = {init_val}f;\\n\")\n","        for i in range(n_trees):\n","            f.write(f\"        score += tree_{i}(x);\\n\")\n","        f.write(f\"        return score;\\n\")\n","        f.write(f\"    }}\\n\\n\")\n","\n","        f.write(f\"private:\\n\")\n","\n","        for i, estimator in enumerate(model.estimators_):\n","            tree = estimator[0].tree_\n","            f.write(f\"    static float tree_{i}(const float* x) {{\\n\")\n","\n","            def recurse(node, depth):\n","                indent = \"        \" + \"    \" * depth\n","                if tree.feature[node] != -2:\n","                    feat_idx = tree.feature[node]\n","                    threshold = tree.threshold[node]\n","                    f.write(f\"{indent}if (x[{feat_idx}] <= {threshold:.6f}f) {{\\n\")\n","                    recurse(tree.children_left[node], depth + 1)\n","                    f.write(f\"{indent}}} else {{\\n\")\n","                    recurse(tree.children_right[node], depth + 1)\n","                    f.write(f\"{indent}}}\\n\")\n","                else:\n","                    val = tree.value[node][0][0]\n","                    f.write(f\"{indent}return {val:.8f}f;\\n\")\n","\n","            recurse(0, 0)\n","            f.write(f\"    }}\\n\\n\")\n","        f.write(f\"}}; \\n\")\n","\n","# Create the codegen directory.\n","os.makedirs(\"experimental/codegen\", exist_ok=True)\n","\n","# Export both hardware targets.\n","export_to_cpp(model_mem, scaler_mem, FEATURES, \"MemoryAdvisor\",\n","              \"experimental/codegen/MemoryAdvisor.h\", \"memory_bound\")\n","export_to_cpp(model_comp, scaler_comp, FEATURES, \"ComputeAdvisor\",\n","              \"experimental/codegen/ComputeAdvisor.h\", \"compute_bound\")\n","\n","# Sync headers to Drive.\n","drive_codegen_path = f\"{DRIVE_FOLDER}/experimental/codegen\"\n","os.makedirs(drive_codegen_path, exist_ok=True)\n","!cp experimental/codegen/*.h \"{drive_codegen_path}/\"\n","\n","print(f\"Inference headers exported to {drive_codegen_path}.\")"],"metadata":{"cellView":"form","id":"RPpSqeFl5jrO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title 7. C++ inference verification\n","import subprocess\n","import os\n","\n","cpp_test_code = \"\"\"\n","#include <iostream>\n","#include <vector>\n","#include <iomanip>\n","#include \"experimental/Advisor.h\"\n","\n","void run_test(const std::string& profile, const std::vector<float>& sample) {\n","    auto advisor = CreateAdvisor(profile);\n","    float prediction = advisor->Predict(sample);\n","    std::cout << std::left << std::setw(16) << profile << \": \"\n","              << std::fixed << std::setprecision(6) << prediction << std::endl;\n","}\n","\n","int main() {\n","    std::vector<float> sample = {112.0f, 112.0f, 32.0f, 32.0f, 3.0f, 1.0f, 1.0f, 8.0f, 1.0f};\n","    std::cout << \"Comparing Profit Ratios for same shape:\\\\n\";\n","    std::cout << \"----------------------------------------\\\\n\";\n","    try {\n","        run_test(\"memory_bound\", sample);\n","        run_test(\"compute_bound\", sample);\n","    } catch (const std::exception& e) {\n","        std::cerr << \"Error: \" << e.what() << std::endl;\n","        return 1;\n","    }\n","    return 0;\n","}\n","\"\"\"\n","\n","!mkdir -p experimental/codegen\n","!cp \"{DRIVE_FOLDER}/experimental/Advisor.h\" experimental/\n","!cp \"{DRIVE_FOLDER}/experimental/Advisor.cpp\" experimental/\n","!cp \"{DRIVE_FOLDER}/experimental/codegen/\"*.h experimental/codegen/\n","\n","with open(\"test_runner.cpp\", \"w\") as f:\n","    f.write(cpp_test_code)\n","\n","# FIX: Remove -Iexperimental and use only -I.\n","# This forces all includes to be resolved from the project root.\n","compile_cmd = \"g++ -std=c++17 test_runner.cpp experimental/Advisor.cpp -o advisor_test -I.\"\n","result = subprocess.run(compile_cmd.split(), capture_output=True, text=True)\n","\n","if result.returncode == 0:\n","    print(\"Compilation successful.\\\\n\")\n","    run_result = subprocess.run([\"./advisor_test\"], capture_output=True, text=True)\n","    print(run_result.stdout)\n","else:\n","    print(\"Compilation failed:\\\\n\")\n","    print(result.stderr)"],"metadata":{"cellView":"form","id":"cYOhaXDIAz4o"},"execution_count":null,"outputs":[]}]}