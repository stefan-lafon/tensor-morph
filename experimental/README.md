# TensorMorph: AI Advisor Layer

This directory contains the infrastructure for the AI-guided optimization policies. TensorMorph uses specialized machine learning models to predict the "profitability" of a graph transformation before it is applied.

## Advisor Creation Pipeline

### 1. Feature Extraction
For every potential fusion point in the TOSA graph, we extract a feature vector representing the state of the IR:
* **Spatial Dimensions**: Input Height, Width, and Channels.
* **Kernel Metadata**: Kernel Height, Width, Stride, and Dilations.
* **Graph Context**: The length of the operation chain and the presence of activations.

### 2. Gradient Boosting Models
Our advisors are built using **Gradient Boosting Regressors**. We train separate models for different hardware bottlenecks:
* **Memory-Bound Profile**: Trained to veto fusions that increase register pressure or kernel complexity on devices with limited bandwidth.
* **Compute-Bound Profile**: Trained to maximize throughput by hiding element-wise math inside existing ALU-heavy loops.

### 3. C++ Transpilation
To ensure zero-latency decisions during compilation, the trained Python models are transpiled into pure C++ headers located in `experimental/codegen/`. 
* The models are represented as efficient decision tree forests.
* They implement the `Advisor` interface, allowing the MLIR pass to swap hardware profiles at runtime via a simple flag.

## Directory Structure
* `Advisor.h / .cpp`: The base interface and factory for the AI decision layer.
* `codegen/`: Autogenerated C++ headers containing the transpiled decision trees.
* `schema.py`: Defines the feature set used by both the Data Generator and the C++ Feature Extractor.