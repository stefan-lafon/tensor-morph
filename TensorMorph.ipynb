{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMPIuIXMUTIfpwHaTT+nkUw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"cellView":"form","id":"gw5tQCFiGnMh"},"outputs":[],"source":["# @title 1. Environment Initialization\n","from google.colab import drive\n","import os\n","\n","if not os.path.exists(\"/content/drive\"):\n","    drive.mount('/content/drive')\n","\n","print(\"--- Installing Toolchain ---\")\n","!wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | sudo apt-key add -\n","!echo \"deb http://apt.llvm.org/jammy/ llvm-toolchain-jammy-18 main\" | sudo tee /etc/apt/sources.list.d/llvm.list\n","!apt-get update -y\n","!apt-get install -y libmlir-18-dev mlir-18-tools llvm-18-dev cmake ninja-build clang-18\n","\n","os.environ[\"CC\"] = \"clang-18\"\n","os.environ[\"CXX\"] = \"clang++-18\""]},{"cell_type":"code","source":["# @title 2. Project Activation\n","import os\n","import shutil\n","\n","DRIVE_ROOT = \"/content/drive/My Drive/projects/TensorMorph\"\n","LOCAL_ROOT = \"/content/tensormorph_local\"\n","\n","# Sync to local\n","if os.path.exists(LOCAL_ROOT):\n","    shutil.rmtree(LOCAL_ROOT)\n","shutil.copytree(DRIVE_ROOT, LOCAL_ROOT)\n","\n","os.chdir(LOCAL_ROOT)\n","\n","# Set permissions\n","!chmod +x tm-cli\n","!chmod +x scripts/benchmark.sh\n","\n","print(\"\\n--- TensorMorph Ready ---\")\n","# This should finally work\n","!./tm-cli --help"],"metadata":{"cellView":"form","id":"qeinlsr6I-D3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title 3. Build TensorMorph Optimizer\n","# This uses the CLI to compile the C++ MLIR passes and tools.\n","!./tm-cli build"],"metadata":{"collapsed":true,"cellView":"form","id":"HZIWEB6HODeb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title 4. Ingest Model to MLIR\n","# This command converts a standard model into the TensorMorph MLIR dialect.\n","# We're passing a flag to create a dummy test model first.\n","!./tm-cli ingest --model sample_mnist --output test.mlir"],"metadata":{"collapsed":true,"id":"xa3w_rdvOzIl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title 5. Verify MLIR Artifact\n","# Inspecting the generated TOSA/TF dialect code\n","!head -n 50 test.mlir"],"metadata":{"collapsed":true,"id":"rEOk6J8zQmjA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title 6. Run TensorMorph Optimizer\n","# This takes the raw TF MLIR and runs our C++ optimization passes\n","!./tm-cli optimize test.mlir"],"metadata":{"id":"eQ4ElBTeRl1m"},"execution_count":null,"outputs":[]}]}