{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "authorship_tag": "ABX9TyNCYNhFvIF+KSGZuPTKKQFC"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "REqmtqFLs-WA",
                "cellView": "form",
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "# @title 1. Environment initialization\n",
                "# This cell mounts Drive and installs the LLVM/MLIR 18 toolchain.\n",
                "# Run this once per session.\n",
                "\n",
                "from google.colab import drive\n",
                "import os\n",
                "\n",
                "# 1. Mount Drive\n",
                "if not os.path.exists(\"/content/drive\"):\n",
                "    drive.mount('/content/drive')\n",
                "\n",
                "# 2. Add LLVM 18 Repository & Install Toolchain\n",
                "# This handles the GPG keys and repo setup that standard apt misses.\n",
                "!wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | sudo apt-key add -\n",
                "!echo \"deb http://apt.llvm.org/jammy/ llvm-toolchain-jammy-18 main\" | sudo tee /etc/apt/sources.list.d/llvm.list\n",
                "!apt-get update -y\n",
                "\n",
                "# Install headers, tools, and the build system\n",
                "!apt-get install -y libmlir-18-dev mlir-18-tools llvm-18-dev cmake ninja-build clang-18\n",
                "\n",
                "# 3. Set standard environment variables\n",
                "os.environ[\"CC\"] = \"clang-18\"\n",
                "os.environ[\"CXX\"] = \"clang++-18\"\n",
                "\n",
                "print(\"\\n--- Setup Complete ---\")"
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "# @title 2. Sync source and build project\n",
                "import os\n",
                "\n",
                "DRIVE_FOLDER = \"/content/drive/My Drive/projects/TensorMorph\"\n",
                "LOCAL_FOLDER = \"/content/tensormorph_local\"\n",
                "\n",
                "%cd /content\n",
                "\n",
                "if os.path.exists(DRIVE_FOLDER):\n",
                "    print(\"Syncing files from Drive...\")\n",
                "    !rm -rf {LOCAL_FOLDER}\n",
                "    !cp -r \"{DRIVE_FOLDER}\" {LOCAL_FOLDER}\n",
                "\n",
                "    os.chdir(LOCAL_FOLDER)\n",
                "    if not os.path.exists(\"build\"):\n",
                "        os.makedirs(\"build\")\n",
                "\n",
                "    os.chdir(\"build\")\n",
                "\n",
                "    # Build with updated source references\n",
                "    !cmake .. -G Ninja \\\n",
                "        -DMLIR_DIR=/usr/lib/llvm-18/lib/cmake/mlir \\\n",
                "        -DLLVM_DIR=/usr/lib/llvm-18/lib/cmake/llvm \\\n",
                "        -DCMAKE_BUILD_TYPE=Debug\n",
                "\n",
                "    !ninja\n",
                "\n",
                "    if os.path.exists(\"tools/tensormorph-opt\"):\n",
                "        print(\"\\n--- Build Successful ---\")\n",
                "        !./tools/tensormorph-opt --version\n",
                "else:\n",
                "    print(f\"Directory not found: {DRIVE_FOLDER}\")"
            ],
            "metadata": {
                "id": "qlK73wr7tOrV",
                "cellView": "form",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "status": "ok",
                    "timestamp": 1766617605133,
                    "user_tz": 480,
                    "elapsed": 20229,
                    "user": {
                        "displayName": "Stefan Lafon",
                        "userId": "17149650627927548318"
                    }
                },
                "outputId": "bc854460-34ed-4508-a4de-487c0517a8f0"
            },
            "execution_count": 49,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "/content\n",
                        "Syncing files from Drive...\n",
                        "-- The C compiler identification is Clang 18.1.8\n",
                        "-- The CXX compiler identification is Clang 18.1.8\n",
                        "-- Detecting C compiler ABI info\n",
                        "-- Detecting C compiler ABI info - done\n",
                        "-- Check for working C compiler: /usr/bin/clang-18 - skipped\n",
                        "-- Detecting C compile features\n",
                        "-- Detecting C compile features - done\n",
                        "-- Detecting CXX compiler ABI info\n",
                        "-- Detecting CXX compiler ABI info - done\n",
                        "-- Check for working CXX compiler: /usr/bin/clang++-18 - skipped\n",
                        "-- Detecting CXX compile features\n",
                        "-- Detecting CXX compile features - done\n",
                        "-- Performing Test HAVE_FFI_CALL\n",
                        "-- Performing Test HAVE_FFI_CALL - Success\n",
                        "-- Found FFI: /usr/lib/x86_64-linux-gnu/libffi.so\n",
                        "-- Could NOT find LibEdit (missing: LibEdit_INCLUDE_DIRS LibEdit_LIBRARIES) \n",
                        "-- Performing Test Terminfo_LINKABLE\n",
                        "-- Performing Test Terminfo_LINKABLE - Success\n",
                        "-- Found Terminfo: /usr/lib/x86_64-linux-gnu/libtinfo.so\n",
                        "-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \"1.2.11\")\n",
                        "-- Found zstd: /usr/lib/x86_64-linux-gnu/libzstd.so\n",
                        "-- Found LibXml2: /usr/lib/x86_64-linux-gnu/libxml2.so (found version \"2.9.13\")\n",
                        "-- Found CURL: /usr/lib/x86_64-linux-gnu/libcurl.so (found version \"7.81.0\")\n",
                        "-- Could NOT find LibEdit (missing: LibEdit_INCLUDE_DIRS LibEdit_LIBRARIES) \n",
                        "-- Configuring done (0.8s)\n",
                        "-- Generating done (0.0s)\n",
                        "-- Build files have been written to: /content/tensormorph_local/build\n",
                        "[4/4] Linking CXX executable tools/tensormorph-opt\u001b[K\n",
                        "\n",
                        "--- Build Successful ---\n",
                        "Ubuntu LLVM version 18.1.8\n",
                        "  Optimized build.\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "# @title 3. Test MLIR (Conv -> Add -> Clamp)\n",
                "%%writefile /content/tensormorph_local/test.mlir\n",
                "module {\n",
                "  func.func @main(%input: tensor<1x4x4x1xf32>) -> tensor<1x4x4x1xf32> {\n",
                "    %c_weights = \"tosa.const\"() {value = dense<0.5> : tensor<1x1x1x1xf32>} : () -> tensor<1x1x1x1xf32>\n",
                "    %c_bias    = \"tosa.const\"() {value = dense<0.0> : tensor<1xf32>} : () -> tensor<1xf32>\n",
                "    %c_add     = \"tosa.const\"() {value = dense<1.0> : tensor<1xf32>} : () -> tensor<1xf32>\n",
                "\n",
                "    // 1. Base Convolution\n",
                "    %0 = \"tosa.conv2d\"(%input, %c_weights, %c_bias) {\n",
                "      dilation = array<i64: 1, 1>,\n",
                "      pad = array<i64: 0, 0, 0, 0>,\n",
                "      stride = array<i64: 1, 1>\n",
                "    } : (tensor<1x4x4x1xf32>, tensor<1x1x1x1xf32>, tensor<1xf32>) -> tensor<1x4x4x1xf32>\n",
                "\n",
                "    // 2. Add operation that should be folded into the bias above\n",
                "    %1 = \"tosa.add\"(%0, %c_add) : (tensor<1x4x4x1xf32>, tensor<1xf32>) -> tensor<1x4x4x1xf32>\n",
                "\n",
                "    // 3. Clamp operation acting as a ReLU (0 to INT64_MAX)\n",
                "    // This should be fused into the Conv2D as an attribute.\n",
                "    %result = \"tosa.clamp\"(%1) {\n",
                "      min_int = 0 : i64,\n",
                "      max_int = 9223372036854775807 : i64, // INT64_MAX\n",
                "      min_fp = 0.0 : f32,\n",
                "      max_fp = 3.40282347e+38 : f32     // FLT_MAX\n",
                "    } : (tensor<1x4x4x1xf32>) -> tensor<1x4x4x1xf32>\n",
                "\n",
                "    return %result : tensor<1x4x4x1xf32>\n",
                "  }\n",
                "}"
            ],
            "metadata": {
                "id": "JIRbH7HKSHEz",
                "cellView": "form"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# @title 4. Run TensorMorph optimizer\n",
                "!/content/tensormorph_local/build/tools/tensormorph-opt \\\n",
                "    --tosa-opt \\\n",
                "    --allow-unregistered-dialect \\\n",
                "    /content/tensormorph_local/test.mlir"
            ],
            "metadata": {
                "id": "TVD4Y9TzSVVg"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# @title 5. Setup lowering utility\n",
                "with open(\"/content/tensormorph_local/lower.sh\", \"w\") as f:\n",
                "    f.write('''#!/bin/bash\n",
                "INPUT_MLIR=$1\n",
                "OUTPUT_LLVM=$2\n",
                "\n",
                "# Structured Pass Pipeline\n",
                "# We nest function-level passes inside the func.func() wrapper\n",
                "# to allow the PassManager to schedule TOSA lowering correctly.\n",
                "/usr/lib/llvm-18/bin/mlir-opt $INPUT_MLIR \\\\\n",
                "    --allow-unregistered-dialect \\\\\n",
                "    --pass-pipeline=\"builtin.module( \\\\\n",
                "        func.func(tosa-to-linalg-named, tosa-to-linalg), \\\\\n",
                "        one-shot-bufferize{allow-unknown-ops function-boundary-type-conversion=identity-layout-map}, \\\\\n",
                "        reconcile-unrealized-casts, \\\\\n",
                "        func.func(convert-linalg-to-loops, convert-scf-to-cf), \\\\\n",
                "        expand-strided-metadata, \\\\\n",
                "        lower-affine, \\\\\n",
                "        convert-arith-to-llvm, \\\\\n",
                "        convert-math-to-llvm, \\\\\n",
                "        finalize-memref-to-llvm, \\\\\n",
                "        convert-func-to-llvm, \\\\\n",
                "        reconcile-unrealized-casts \\\\\n",
                "    )\" \\\\\n",
                "    -o $OUTPUT_LLVM\n",
                "''')\n",
                "\n",
                "!chmod +x /content/tensormorph_local/lower.sh\n",
                "print(\"Lowering utility script updated with explicit pass nesting.\")"
            ],
            "metadata": {
                "id": "eZkQ9BTNKA-0"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# @title 6. Generate execution wrapper\n",
                "with open(\"/content/tensormorph_local/benchmark_wrapper.mlir\", \"w\") as f:\n",
                "    f.write('''\n",
                "module {\n",
                "  // Global definitions for our input data\n",
                "  memref.global \"private\" constant @input_data : memref<1x4x4x1xf32> = dense<1.0>\n",
                "  memref.global \"private\" constant @weight_data : memref<1x1x1x1xf32> = dense<0.5>\n",
                "  memref.global \"private\" constant @bias_data : memref<1xf32> = dense<0.0>\n",
                "\n",
                "  // Updated signature to use memrefs directly\n",
                "  func.func private @main(memref<1x4x4x1xf32>, memref<1x1x1x1xf32>, memref<1xf32>) -> memref<1x4x4x1xf32>\n",
                "\n",
                "  func.func @benchmark_entry() {\n",
                "    %in = memref.get_global @input_data : memref<1x4x4x1xf32>\n",
                "    %w  = memref.get_global @weight_data : memref<1x1x1x1xf32>\n",
                "    %b  = memref.get_global @bias_data : memref<1xf32>\n",
                "\n",
                "    // Call @main using the pre-allocated memory\n",
                "    %res = func.call @main(%in, %w, %b) : (memref<1x4x4x1xf32>, memref<1x1x1x1xf32>, memref<1xf32>) -> memref<1x4x4x1xf32>\n",
                "\n",
                "    return\n",
                "  }\n",
                "}\n",
                "''')\n",
                "print(\"Benchmark wrapper updated to use stable Memref Globals.\")"
            ],
            "metadata": {
                "id": "5YpbvkGQKDQq",
                "cellView": "form"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# @title 7. Performance benchmarking\n",
                "import subprocess\n",
                "import time\n",
                "import numpy as np\n",
                "\n",
                "def run_bench(mlir_file, label, iterations=50):\n",
                "    print(f\"Executing: {label}\")\n",
                "\n",
                "    # 1. Merge the test IR with the wrapper\n",
                "    combined_ir = \"/content/tensormorph_local/combined.mlir\"\n",
                "    subprocess.run(f\"cat {mlir_file} /content/tensormorph_local/benchmark_wrapper.mlir > {combined_ir}\", shell=True, check=True)\n",
                "\n",
                "    # 2. Lower to LLVM\n",
                "    llvm_file = \"/content/tensormorph_local/exec.llvm.mlir\"\n",
                "    result = subprocess.run([\"/content/tensormorph_local/lower.sh\", combined_ir, llvm_file], capture_output=True, text=True)\n",
                "\n",
                "    if result.returncode != 0:\n",
                "        print(f\"Lowering failed for {label}:\")\n",
                "        print(result.stderr)\n",
                "        return None\n",
                "\n",
                "    # 3. Time the execution\n",
                "    cmd = [\n",
                "        \"/usr/lib/llvm-18/bin/mlir-cpu-runner\", llvm_file,\n",
                "        \"-e\", \"benchmark_entry\", \"-entry-point-result=void\",\n",
                "        \"-shared-libs=/usr/lib/llvm-18/lib/libmlir_c_runner_utils.so\"\n",
                "    ]\n",
                "\n",
                "    latencies = []\n",
                "    # Warmup\n",
                "    for _ in range(5):\n",
                "        subprocess.run(cmd, capture_output=True)\n",
                "\n",
                "    for _ in range(iterations):\n",
                "        start = time.perf_counter()\n",
                "        subprocess.run(cmd, capture_output=True)\n",
                "        latencies.append((time.perf_counter() - start) * 1000)\n",
                "\n",
                "    avg = np.mean(latencies)\n",
                "    std = np.std(latencies)\n",
                "    print(f\"Average: {avg:.4f} ms (+/- {std:.4f})\")\n",
                "    return avg\n",
                "\n",
                "base_ir = \"/content/tensormorph_local/test.mlir\"\n",
                "opt_ir = \"/content/tensormorph_local/test_opt.mlir\"\n",
                "\n",
                "# Generate optimized version\n",
                "!/content/tensormorph_local/build/tools/tensormorph-opt --tosa-opt --allow-unregistered-dialect {base_ir} -o {opt_ir}\n",
                "\n",
                "t_base = run_bench(base_ir, \"Baseline (Unoptimized)\")\n",
                "t_opt = run_bench(opt_ir, \"Fused (TensorMorph)\")\n",
                "\n",
                "if t_base and t_opt:\n",
                "    speedup = (t_base / t_opt)\n",
                "    print(f\"Total Speedup: {speedup:.2f}x\")"
            ],
            "metadata": {
                "id": "RYiSgdBzKE4K",
                "cellView": "form"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# @title 8. Run regression suite\n",
                "import os\n",
                "import subprocess\n",
                "\n",
                "# Drive and Local paths\n",
                "DRIVE_TEST_DIR = f\"{DRIVE_FOLDER}/tests\"\n",
                "LOCAL_TEST_DIR = \"/content/tensormorph_local/tests\"\n",
                "OPT_TOOL = \"/content/tensormorph_local/build/tools/tensormorph-opt\"\n",
                "FILECHECK = \"/usr/lib/llvm-18/bin/FileCheck\"\n",
                "\n",
                "# 1. Sync latest tests from Drive\n",
                "if os.path.exists(DRIVE_TEST_DIR):\n",
                "    !cp -r \"{DRIVE_TEST_DIR}\" /content/tensormorph_local/\n",
                "    print(\"Tests synced from Drive.\\n\")\n",
                "else:\n",
                "    print(f\"Warning: Test directory not found in Drive: {DRIVE_TEST_DIR}\")\n",
                "\n",
                "# 2. Execute FileCheck on all .mlir files in the test directory\n",
                "tests = [f for f in os.listdir(LOCAL_TEST_DIR) if f.endswith(\".mlir\")]\n",
                "passed = 0\n",
                "\n",
                "for test_file in sorted(tests):\n",
                "    test_path = os.path.join(LOCAL_TEST_DIR, test_file)\n",
                "    # Run the tool and pipe to FileCheck\n",
                "    cmd = f\"{OPT_TOOL} --tosa-opt {test_path} | {FILECHECK} {test_path}\"\n",
                "\n",
                "    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
                "\n",
                "    if result.returncode == 0:\n",
                "        print(f\"[PASS] {test_file}\")\n",
                "        passed += 1\n",
                "    else:\n",
                "        print(f\"[FAIL] {test_file}\")\n",
                "        print(\"--- Error Output ---\")\n",
                "        print(result.stderr)\n",
                "\n",
                "print(f\"\\nSummary: {passed}/{len(tests)} tests passed.\")"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "WX_gAnZljSBO",
                "executionInfo": {
                    "status": "ok",
                    "timestamp": 1766617698513,
                    "user_tz": 480,
                    "elapsed": 310,
                    "user": {
                        "displayName": "Stefan Lafon",
                        "userId": "17149650627927548318"
                    }
                },
                "outputId": "218cec49-108a-492a-e8a2-694a2b610a8d"
            },
            "execution_count": 52,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Tests synced from Drive.\n",
                        "\n",
                        "[PASS] conv_add_clamp.mlir\n",
                        "[PASS] conv_mul_fusion.mlir\n",
                        "[PASS] conv_sub_fusion.mlir\n",
                        "[PASS] identity_add.mlir\n",
                        "[PASS] identity_mul.mlir\n",
                        "[PASS] identity_sub.mlir\n",
                        "\n",
                        "Summary: 6/6 tests passed.\n"
                    ]
                }
            ]
        }
    ]
}